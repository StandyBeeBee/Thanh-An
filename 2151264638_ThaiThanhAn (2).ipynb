{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9013068a-65e4-4c19-bae2-0f10550e4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "a = 2151264638 % 16\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae8ebbb-25e6-4d7c-909a-b726e2b2d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler,PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import BayesianGaussianMixture,GaussianMixture\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_score, accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from filterpy.kalman import KalmanFilter #Kalman\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc1a0a6-f2bf-4a70-aca3-bc194e79cc9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x88 in position 2: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGia_SMP_TS21_5_2024.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNg?y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:980\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    967\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    968\u001b[0m     dialect,\n\u001b[0;32m    969\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    978\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:629\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    626\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1529\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1804\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1801\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:578\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:667\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:878\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:895\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2055\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x88 in position 2: invalid start byte"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Gia_SMP_TS21_5_2024.csv\",index_col = 'Ng?y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d342178-29b3-4e34-ae23-f0424d9eb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268d48f-7f84-405a-9499-8ecf3a82661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats= ['15', '16', '17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e4e8f-44b1-4f94-9813-8954963d8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = PowerTransformer()\n",
    "X=transformer.fit_transform(df[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72b457-fa48-4a0f-b711-78472c37fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.5,random_state=1)\n",
    "pca.fit(X)\n",
    "PCA_ds = pd.DataFrame(pca.transform(df[feats]), columns=([\"col\"]))\n",
    "PCA_ds.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92490019-44bc-49bf-85d5-f279e28e12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elbow Method to determine the number of clusters to be formed:')\n",
    "Elbow_M = KElbowVisualizer(KMeans(random_state=23), k=(4,12))\n",
    "Elbow_M.fit(X)\n",
    "Elbow_M.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f361fd-6967-4424-b60f-e1668f26076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING GAUSIAN\n",
    "BGM = BayesianGaussianMixture(n_components=7,covariance_type='full',random_state=1,n_init=15)\n",
    "# fit model and predict clusters\n",
    "preds = BGM.fit_predict(X)\n",
    "PCA_ds[\"Clusters\"] = preds\n",
    "#Adding the Clusters feature to the orignal dataframe.\n",
    "df[\"Clusters\"]= preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8acd0-90f1-4d04-a60a-febc26d58710",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=BGM.predict_proba(X)# Calcualting the probabilities of each prediction\n",
    "df_new=pd.DataFrame(X,columns=feats) \n",
    "df_new[[f'predict_proba_{i}' for i in range(6)]]=pp # creating new dataframe columns of probabilites \n",
    "df_new['preds']=preds\n",
    "df_new['predict_proba']=np.max(pp,axis=1)\n",
    "df_new['predict']=np.argmax(pp,axis=1)\n",
    "    \n",
    "train_index=np.array([])\n",
    "for n in range(7):\n",
    "    n_inx=df_new[(df_new.preds==n) & (df_new.predict_proba > 0.68)].index\n",
    "    train_index = np.concatenate((train_index, n_inx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcea929-fe29-4e2d-bb08-7fc1160f0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=df_new.loc[train_index][feats]\n",
    "y=df_new.loc[train_index]['preds']\n",
    "\n",
    "params_lgb = {'learning_rate': 0.06,'objective': 'multiclass','boosting': 'gbdt','n_jobs': -1,'verbosity': -1, 'num_classes':7} \n",
    "\n",
    "model_list=[]\n",
    "\n",
    "gkf = StratifiedKFold(11)\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf.split(X_new,y)):   \n",
    "\n",
    "    tr_dataset = lgb.Dataset(X_new.iloc[train_idx],y.iloc[train_idx],feature_name = feats)\n",
    "    vl_dataset = lgb.Dataset(X_new.iloc[valid_idx],y.iloc[valid_idx],feature_name = feats)\n",
    "    \n",
    "    model = lgb.train(params = params_lgb, \n",
    "                train_set = tr_dataset, \n",
    "                valid_sets =  vl_dataset, \n",
    "                num_boost_round = 5000, \n",
    "                callbacks=[ lgb.early_stopping(stopping_rounds=300, verbose=False), lgb.log_evaluation(period=200)])  \n",
    "    \n",
    "    model_list.append(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678a52a-0283-4e5b-8793-34d7afd2b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.argmax(lgb_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58dafb-7c83-4613-8d91-122084e6362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Predicted=np.argmax(lgb_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0be8de-abf0-49e0-a9b7-49abefe64075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING EDA\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Display the number of missing values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40916db2-cf9d-4bb0-bc62-d9bacb51b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values (example: filling with mean or removing)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "# data.dropna(inplace=True)  # Alternatively, remove rows with missing values\n",
    "\n",
    "# Convert data types if needed\n",
    "# data['column_name'] = data['column_name'].astype('desired_type')\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b162cc-ec37-463e-b3c9-38de63ad127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "print(df.describe())\n",
    "\n",
    "# Summary statistics for categorical columns\n",
    "print(df.describe())\n",
    "\n",
    "# Display the distribution of a specific column\n",
    "print(df.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3c1f6-0b1e-4555-b98d-78f298054b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numerical columns\n",
    "df.hist(figsize=(10, 8))\n",
    "plt.show()\n",
    "\n",
    "# Boxplots to visualize outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "# Specific plots for categorical data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(df['categorical_column'])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for two numerical columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='9', y='10', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f1f72-482e-4592-a6ee-823180832f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Display correlation matrix\n",
    "print(corr_matrix)\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b40d9-c940-4838-8d42-fa08f5fac792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using IQR to detect outliers\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter out outliers\n",
    "df_outliers_filtered = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(f'Original data shape: {df.shape}')\n",
    "print(f'Data shape after outlier removal: {df_outliers_filtered.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36d309-cb48-4d59-a3aa-4c9a0294202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kamal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "n_timesteps = 50\n",
    "true_position = np.linspace(0, 100, n_timesteps)\n",
    "measurements = true_position + np.random.normal(0, 10, n_timesteps)\n",
    "\n",
    "plt.plot(true_position, label='True Position')\n",
    "plt.plot(measurements, label='Measurements', linestyle='dashed')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c39b2-9654-4c68-80d0-1449a5c934da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kalman_filter(measurements, process_variance, measurement_variance, estimated_measurement_variance):\n",
    "    n_timesteps = len(measurements)\n",
    "    \n",
    "    # Allocate space for arrays\n",
    "    estimated_position = np.zeros(n_timesteps)\n",
    "    estimated_error = np.zeros(n_timesteps)\n",
    "    kalman_gain = np.zeros(n_timesteps)\n",
    "    \n",
    "    # Initial guesses\n",
    "    estimated_position[0] = measurements[0]\n",
    "    estimated_error[0] = 1.0\n",
    "    \n",
    "    for t in range(1, n_timesteps):\n",
    "        # Prediction step\n",
    "        estimated_position[t] = estimated_position[t-1]\n",
    "        estimated_error[t] = estimated_error[t-1] + process_variance\n",
    "        \n",
    "        # Update step\n",
    "        kalman_gain[t] = estimated_error[t] / (estimated_error[t] + measurement_variance)\n",
    "        estimated_position[t] += kalman_gain[t] * (measurements[t] - estimated_position[t])\n",
    "        estimated_error[t] = (1 - kalman_gain[t]) * estimated_error[t]\n",
    "    \n",
    "    return estimated_position, estimated_error, kalman_gain\n",
    "\n",
    "# Parameters\n",
    "process_variance = 1.0  # Variance in the process\n",
    "measurement_variance = 10.0  # Variance in the measurements\n",
    "estimated_measurement_variance = 1.0  # Initial estimation of the measurement variance\n",
    "\n",
    "# Apply Kalman filter\n",
    "estimated_position, estimated_error, kalman_gain = kalman_filter(\n",
    "    measurements, process_variance, measurement_variance, estimated_measurement_variance\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plt.plot(true_position, label='True Position')\n",
    "plt.plot(measurements, label='Measurements', linestyle='dashed')\n",
    "plt.plot(estimated_position, label='Kalman Filter Estimate')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d8f93-165a-4fa6-b69f-bc96b8d27566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING ARIMA\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Load dataset\n",
    "data = pd.read_csv('Gia_SMP_TS21_5_2024.csv', index_col='Ng?y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810ef59-253c-4093-b99e-8cf05bcccdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.8)  # 80% for training, 20% for testing\n",
    "train_data, test_data = data[:train_size], data[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f5988-f495-46d2-bedd-0650dab1ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARIMA model parameters (p, d, q)\n",
    "p = 5  # Autoregression (AR) order\n",
    "d = 1  # Integrated (I) order (degree of differencing)\n",
    "q = 0  # Moving Average (MA) order\n",
    "\n",
    "# Initialize and fit ARIMA model\n",
    "arima_model = ARIMA(train_data, order=(p, d, q))\n",
    "arima_result = arima_model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc82aa-5994-4d38-aa7a-677d7d695a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_data, predictions))\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a859e2-a9ef-466f-813a-60d2080844a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed vs. predicted values\n",
    "plt.plot(test_data, label='Observed')\n",
    "plt.plot(test_data.index, predictions, color='red', label='Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('ARIMA Model Forecast')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af2a54-2bec-466b-bc1d-e034f3e37bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
